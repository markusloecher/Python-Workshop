[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Exercises for Introduction to Data Science in Python",
    "section": "",
    "text": "This is a collection of exercises that accompany the python workshop."
  },
  {
    "objectID": "Lab1.html",
    "href": "Lab1.html",
    "title": "1  Lists, Loops, Conditions",
    "section": "",
    "text": "Lists\n\nDataCamp, Introduction to Python, Chap 2\n\nLoops\n\nDataCamp, Intermediate Python, Chap 4\n\nConditions\n\nDataCamp, Intermediate Python, Chap 3\n\n\n\nManipulating lists of lists\nThe following list of lists contains names of sections in a house and their area.\n\nExtract the area corresponding to kitchen\nString Tasks:\n\nExtract the first letters of each string\nCapitalize all strings\nReplace all occurrences of “room” with “rm”\ncount the number of “l” in “hallway”\n\nInsert a “home office” with area 10.75 after living room\nAppend the total area to the end of the list\nBoolean operations:\n\nGenerate one True and one False by comparing areas\nGenerate one True and one False by comparing names\n\n\n\nhouse = [['hallway', 11.25],\n ['kitchen', 18.0],\n ['living room', 20.0],\n ['bedroom', 10.75],\n ['bathroom', 9.5]]\n\n\n\nAutomation by iterating\nfor loops are a powerful way of automating MANY otherwise tedious tasks that repeat.\n\nRepeat the tasks 2 and 4 from above by using a for loop\n\nusing enumerate\nusing range\n\nCreate two separates new lists which contain only the names and areas separately\nClever Carl: Compute\n\n\\[\n\\sum_{i=1}^{100}{i}\n\\]\n\nlist(range(5))\n\n[0, 1, 2, 3, 4]\n\n\n\n\nConditions\n\nFind the max of the areas by using if inside a for loop\nPrint those elements of the list with\n\narea \\(> 15\\)\nstrings that contain “room” (or “rm” after your substitution)"
  },
  {
    "objectID": "Lab2.html",
    "href": "Lab2.html",
    "title": "2  Functions, Dictionaries",
    "section": "",
    "text": "Functions\n\nDataCamp, Introduction to Python, Chap 3\n\nDictionaries\n\nDataCamp, Intermediate Python, Chap 2\n\nIntroduction to numpy\n\nDataCamp, Introduction to Python, Chap 4\n\n\n\nFunctions\nFunctions are essential building blocks to reuse code and to modularize code.\nWe have already seen and used many built-in functions/methods such as print(), len(), max(), round(), index(), capitalize(), etc..\n\nareas = [11.25, 18.0, 20.0, 10.75, 10.75, 9.5]\nprint(max(areas))\nprint(len(areas))\nprint(round(10.75,1))\nprint(areas.index(18.0))\n\n20.0\n6\n10.8\n1\n\n\nBut of course we want to define our own functions as well ! As a rule of thumb, if you anticipate needing to repeat the same or very similar code more than once, it may be worth writing a reusable function. Functions can also help make your code more readable by giving a name to a group of Python statements.\nFor example, we computed the BMI previously as follows:\n\nheight = 1.79\nweight = 68.7\nbmi = weight/height**2\nprint(bmi)\n\n21.44127836209856\n\n\nFunctions are declared with the def keyword. A function contains a block of code with an optional use of the return keyword:\n\ndef compute_bmi(height, weight):\n    return weight/height**2\n\ncompute_bmi(1.79, 68.7)\n\n21.44127836209856\n\n\nEach function can have positional arguments and keyword arguments. Keyword arguments are most commonly used to specify default values or optional arguments. For example:\n\ndef compute_bmi(height, weight, ndigits=2):\n    return round(weight/height**2, ndigits)\n\nprint(compute_bmi(1.79, 68.7))\nprint(compute_bmi(1.79, 68.7,4))\n\n21.44\n21.4413\n\n\n\nMultiple Return Values\nare easily possible in python:\n\ndef compute_bmi(height, weight, ndigits=2):\n    bmi = round(weight/height**2, ndigits)\n    #https://www.cdc.gov/healthyweight/assessing/index.html#:~:text=If%20your%20BMI%20is%20less,falls%20within%20the%20obese%20range.\n    if bmi < 18.5:\n        status=\"underweight\"\n    elif bmi <= 24.9:\n        status=\"healthy\"\n    elif bmi <= 29.9:\n        status=\"underweight\"\n    elif bmi >= 30:#note that a simple else would suffice here!\n        status=\"obese\"\n    return bmi, status\n\nprint(compute_bmi(1.79, 68.7))\nprint(compute_bmi(1.79, 55))\n\n(21.44, 'healthy')\n(17.17, 'underweight')\n\n\nRecall from the previous lab how we\n\nfound the largest room,\ncomputed the sum of integers from 1 to 100\n\n\n#find the maximum area:\nareas = [11.25, 18.0, 20.0, 10.75, 10.75, 9.5]\ncurrentMax = areas[0] # initialize to the first area seen\n\nfor a in areas:\n  if a > currentMax:\n    currentMax = a\n\nprint(\"The max is:\", currentMax)\n\nThe max is: 20.0\n\n\n\n#Clever IDB students: Compute the sum from 1 to 100:\nTotal =0\n\nfor i in range(101):#strictly speaking we are adding the first  0 \n  Total = Total + i\n  #Total += i\n\nprint(Total)\n\n\n\nTasks\nWrite your own function\n\nto find the min and max of a list\nto compute the Gauss sum with defaukt values \\(m=1, n=100\\)\n\n\\[\n\\sum_{i=m}^{n}{i}\n\\]\n\n\nNamespaces and Scope\nFunctions seem straightforward. But one of the more confusing aspects in the beginning is the concept that we can have multiple instances of the same variable!\nFunctions can access variables created inside the function as well as those outside the function in higher (or even global) scopes. An alternative and more descriptive name describing a variable scope in Python is a namespace. Any variables that are assigned within a function by default are assigned to the local namespace. The local namespace is created when the function is called and is immediately populated by the function’s arguments. After the function is finished, the local namespace is destroyed.\nExamples:\n\nheight = 1.79\nweight = 68.7\nbmi = weight/height**2\n#print(\"height, weight, bmi OUTSIDE the function:\",height, weight,bmi)\n\ndef compute_bmi(h, w):\n    height = h\n    weight = w\n    bmi = round(weight/height**2,2)\n    status=\"healthy\"\n    print(\"height, weight, bmi INSIDE the function:\",height, weight,bmi)\n    print(\"status:\", status)\n    return bmi\n\ncompute_bmi(1.55, 50)\n\nprint(\"height, weight, bmi OUTSIDE the function:\",height, weight,bmi)\n#print(status)\n\nheight, weight, bmi INSIDE the function: 1.55 50 20.81\nstatus: healthy\nheight, weight, bmi OUTSIDE the function: 1.79 68.7 21.44127836209856\n\n\n\n\n\nDictionaries\nA dictionary is basically a lookup table. It stores a collection of key-value pairs, where key and value are Python objects. Each key is associated with a value so that a value can be conveniently retrieved, inserted, modified, or deleted given a particular key.\nThe dictionary or dict may be the most important built-in Python data structure. In other programming languages, dictionaries are sometimes called hash maps or associative arrays.\n\n#This was the house defined as a list of lists:\nhouse = [['hallway', 11.25],\n ['kitchen', 18.0],\n ['living room', 20.0],\n ['bedroom', 10.75],\n ['bathroom', 9.5]]\n\n#Remember all the disadvantages of accessing elements\n\n#Better as a lookup table:\nhouse = {'hallway': 11.25,\n    'kitchen': 18.0,\n    'living room': 20.0,\n    'bedroom': 10.75,\n    'bathroom': 9.5}\n\n\neurope = {'spain':'madrid', 'france' : 'paris'}\nprint(europe[\"spain\"])\nprint(\"france\" in europe)\nprint(\"paris\" in europe)#only checks the keys!\neurope[\"germany\"] = \"berlin\"\nprint(europe.keys())\nprint(europe.values())\n\nmadrid\nTrue\nFalse\ndict_keys(['spain', 'france', 'germany'])\ndict_values(['madrid', 'paris', 'berlin'])\n\n\nIf you need to iterate over both the keys and values, you can use the items method to iterate over the keys and values as 2-tuples:\n\n#print(list(europe.items()))\n\nfor country, capital in europe.items():\n    print(capital, \"is the capital of\", country)\n\nmadrid is the capital of spain\nparis is the capital of france\nberlin is the capital of germany\n\n\nNote: You can use integers as keys as well. However -unlike in lists- one should not think of them as positional indices!\n\n#Assume you have a basement:\nhouse[0] = 21.5\nhouse\n\n{'hallway': 11.25,\n 'kitchen': 18.0,\n 'living room': 20.0,\n 'bedroom': 10.75,\n 'bathroom': 9.5,\n 0: 21.5}\n\n\n\n#And there is a difference between the string and the integer index!\nhouse[\"0\"] = 30.5\nhouse\n\n{'hallway': 11.25,\n 'kitchen': 18.0,\n 'living room': 20.0,\n 'bedroom': 10.75,\n 'bathroom': 9.5,\n 0: 21.5}\n\n\nCategorize a list of words by their first letters as a dictionary of lists:\n\nwords = [\"apple\", \"bat\", \"bar\", \"atom\", \"book\"]\n\nby_letter = {}\n\nfor word in words:\n     letter = word[0]\n     if letter not in by_letter:\n        by_letter[letter] = [word]\n     else:\n         by_letter[letter].append(word)\n\n{'a': ['apple', 'atom'], 'b': ['bat', 'bar', 'book']}\n\n\n\nTasks\n\nFind the maximum of the areas of the houses\nRemove the two last entries.\nWrite a function named word_count that takes a string as input and returns a dictionary with each word in the string as a key and the number of times it appears as the value.\n\n\n\n\nIntroduction to numpy\nNumPy, short for Numerical Python, is one of the most important foundational packages for numerical computing in Python.\n\nVectorized, fast mathematical operations.\nKey features of NumPy is its N-dimensional array object, or ndarray\n\n\nheight = [1.79, 1.85, 1.95, 1.55]\nweight = [70, 80, 85, 65]\n\n#bmi = weight/height**2\n\n\nimport numpy as np\n\nheight = np.array([1.79, 1.85, 1.95, 1.55])\nweight = np.array([70, 80, 85, 65])\n\nbmi = weight/height**2\nnp.round(bmi,2)\n\narray([21.84700852, 23.37472608, 22.35371466, 27.05515088])"
  },
  {
    "objectID": "Lab3.html",
    "href": "Lab3.html",
    "title": "3  Numpy Arrays, Randomness",
    "section": "",
    "text": "Numpy Arrays\n\nSlicing and Accessing\nProperly using axis\n\nRandom Data Generation\n\nRandom integers, permutations and sampling\n\nSimulating Probabilistic Events\n\n\n\n\n\nNumpy Arrays\n\nTasks\n\nGenerate a sequence from 1 to 64\nPrint every other element\nUsing Boolean indexing: print only those numbers that are greater than 10\nReshape into a \\(8x8\\) matrix and print its “shape”\nCompute the colum and row sums\n\n\n\n\nRandom Data Generation\n\n“Flip a fair coin” \\(20\\) times and save into an array. Note that instead of using “heads/tails” you should “code” the outcome as 0/1.\nRandomly “draw” 2 integers without replacement from the sequence 1-5. Repeat this process 30 times and store the results in an array.\nCompute the counts\n\n\n\nSimulating Probabilistic Events\n\nOverbooking flights: airlines\nHome Office days: planning office capacities and minimizing social isolation"
  },
  {
    "objectID": "Lab4.html",
    "href": "Lab4.html",
    "title": "4  Probabilistic Events",
    "section": "",
    "text": "import numpy as np\nfrom numpy.random import default_rng\n\n\nSimulating Probabilistic Events\n\nBiased Coin: Simulate 365 days with a \\(p =\\frac{1}{4}\\) chance of being sunny (=1). Hint: exploit the fact that \\(p\\) is a fraction!\nBirthday problem Change the “birthday code” into a function with “n = number of people in a room” as an argument. (What other arguments might be useful?) Execute this function for \\(n=10, 25, 50\\).\nOverbooking flights: Imagine an airline sold \\(105\\) tickets on a flight with \\(100\\) seats. Assuming there is a \\(10\\%\\) no-show probability per passenger, “compute” (simulate) the probability that the airline will need to pay someone to not board."
  },
  {
    "objectID": "Lab5.html",
    "href": "Lab5.html",
    "title": "5  Pandas",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\n!pip install gapminder\nfrom gapminder import gapminder\n\n\nheight = np.array([1.79, 1.85, 1.95, 1.55])\nweight = np.array([70, 80, 85, 65])\nhw = np.array([height, weight]).transpose()\n\nhw\n\narray([[ 1.79, 70.  ],\n       [ 1.85, 80.  ],\n       [ 1.95, 85.  ],\n       [ 1.55, 65.  ]])\n\n\n\ndf = pd.DataFrame(hw , columns = [\"height\", \"weight\"]) \nprint(df)\n\n   height  weight\n0    1.79    70.0\n1    1.85    80.0\n2    1.95    85.0\n3    1.55    65.0\n\n\n\ndf = pd.DataFrame(hw , columns = [\"height\", \"weight\"],\n                  index = [\"Peter\", \"Matilda\", \"Bee\", \"Bee\"]) \nprint(df)\n\n         height  weight\nPeter      1.79    70.0\nMatilda    1.85    80.0\nBee        1.95    85.0\nBee        1.55    65.0\n\n\nCan you extract:\n\nAll weights\nPeter’s height\nBee’s full info\nthe average height\nget all persons with height greater than 180cm\n\n\nGapminder\n\ngapminder.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      country\n      continent\n      year\n      lifeExp\n      pop\n      gdpPercap\n    \n  \n  \n    \n      0\n      Afghanistan\n      Asia\n      1952\n      28.801\n      8425333\n      779.445314\n    \n    \n      1\n      Afghanistan\n      Asia\n      1957\n      30.332\n      9240934\n      820.853030\n    \n    \n      2\n      Afghanistan\n      Asia\n      1962\n      31.997\n      10267083\n      853.100710\n    \n    \n      3\n      Afghanistan\n      Asia\n      1967\n      34.020\n      11537966\n      836.197138\n    \n    \n      4\n      Afghanistan\n      Asia\n      1972\n      36.088\n      13079460\n      739.981106\n    \n  \n\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\nTasks\n\nfind the unique years\nget all rows with year 1952\nget all rows from 1952:1962\nget all rows from Afghanistan to Albania"
  },
  {
    "objectID": "DS_Exercise1.html",
    "href": "DS_Exercise1.html",
    "title": "6  Titanic",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n#pd.options.mode.chained_assignment = None # disable chained assignment warning\nimport seaborn as sns\nfrom scipy.stats import norm"
  },
  {
    "objectID": "DS_Exercise1.html#explore-the-titanic-data",
    "href": "DS_Exercise1.html#explore-the-titanic-data",
    "title": "6  Titanic",
    "section": "Explore the Titanic Data",
    "text": "Explore the Titanic Data\n\ntitanic = sns.load_dataset('titanic')\ntitanic.head()\n\n\n\n\n\n  \n    \n      \n      survived\n      pclass\n      sex\n      age\n      sibsp\n      parch\n      fare\n      embarked\n      class\n      who\n      adult_male\n      deck\n      embark_town\n      alive\n      alone\n    \n  \n  \n    \n      0\n      0\n      3\n      male\n      22.0\n      1\n      0\n      7.2500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      False\n    \n    \n      1\n      1\n      1\n      female\n      38.0\n      1\n      0\n      71.2833\n      C\n      First\n      woman\n      False\n      C\n      Cherbourg\n      yes\n      False\n    \n    \n      2\n      1\n      3\n      female\n      26.0\n      0\n      0\n      7.9250\n      S\n      Third\n      woman\n      False\n      NaN\n      Southampton\n      yes\n      True\n    \n    \n      3\n      1\n      1\n      female\n      35.0\n      1\n      0\n      53.1000\n      S\n      First\n      woman\n      False\n      C\n      Southampton\n      yes\n      False\n    \n    \n      4\n      0\n      3\n      male\n      35.0\n      0\n      0\n      8.0500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      True\n    \n  \n\n\n\n\n\ntitanic[['survived']].mean()\n\nsurvived    0.383838\ndtype: float64\n\n\n\nTask\nWe have seen a strong dependence of the outcome on the two “variables”/“features”/“regressors” pclass and sex. The natural question is whether there could be more factors “correlated with”/“influencing”/“affecting” Survival.\n\nDoes the port of embarkment matter ?\n\n(MC) What is the distribution (counts) of embarkment? (Hint: look at pd.value_counts )\n\nA 168, 77, 644\nB 158, 80, 636\nC 170, 75, 639\nD 164, 79, 667\n\n(MC) What are the survival rates for Southampton as a function of pclass?\n\nA 0.54, 0.42, 0.17\nB 0.62, 0.39, 0.15\nC 0.58, 0.46, 0.19\nD 0.56, 0.37, 0.21\n\nDo the survival rates “look” different from Cherbourg ?\nHow would you make sure that the observed differences are not due to chance ?\n\nDoes the fare paid matter ?\n\nHow would you quantify/visualize this ?\nWhat is the fundamental difference between the previous relationship of two variables ?\nHave you heard of the terms confounding or confounders or marginal dependence versus conditional dependence ?\nDiscuss dependencies among the features. Revisit the port of embarkment question in this light !\n\nDoes age matter ?\n\n(MC) What is the survival rate for passengers below the age of 18?\n\nA 0.47\nB 0.74\nC 0.54\nD 0.45\n\n(MC) What are the survival rates for passengers below the age of 18 stratified by pclass?\n\nA 0.91, 0.87, 0.36\nB 0.93, 0.88, 0.38\nC 0.95, 0.93, 0.37\nD 0.92, 0.91, 0.37\n\nHow would you make sure that the observed differences are not due to chance ?"
  },
  {
    "objectID": "Lab6.html",
    "href": "Lab6.html",
    "title": "7  Missing Data",
    "section": "",
    "text": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n#!pip install gapminder\n#from gapminder import gapminder\n\n\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\nMounted at /content/drive\n\n\n\n#read in the data\nrootPath = \"/content/drive/MyDrive/\"#same for all of you\nloecherPath = \"Teaching/SS2023/IntroCoding/datasets/\"\ndf = pd.read_csv(rootPath + loecherPath + \"train.csv\")\n#df = pd.read_csv('/content/drive/MyDrive/Teaching/SS2023/IntroCoding/datasets/train.csv')\n\n\n#or\nurl =\"https://drive.google.com/file/d/1hzvcubf2B8PKtjG4OAcytQKwOlESkBvW/view?usp=sharing\"\nurl='https://drive.google.com/uc?id=' + url.split('/')[-2]\ndf = pd.read_csv(url)\ndf.head()\n\n\ndf.info()\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1460 entries, 0 to 1459\nData columns (total 81 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   Id             1460 non-null   int64  \n 1   MSSubClass     1460 non-null   int64  \n 2   MSZoning       1460 non-null   object \n 3   LotFrontage    1201 non-null   float64\n 4   LotArea        1460 non-null   int64  \n 5   Street         1460 non-null   object \n 6   Alley          91 non-null     object \n 7   LotShape       1460 non-null   object \n 8   LandContour    1460 non-null   object \n 9   Utilities      1460 non-null   object \n 10  LotConfig      1460 non-null   object \n 11  LandSlope      1460 non-null   object \n 12  Neighborhood   1460 non-null   object \n 13  Condition1     1460 non-null   object \n 14  Condition2     1460 non-null   object \n 15  BldgType       1460 non-null   object \n 16  HouseStyle     1460 non-null   object \n 17  OverallQual    1460 non-null   int64  \n 18  OverallCond    1460 non-null   int64  \n 19  YearBuilt      1460 non-null   int64  \n 20  YearRemodAdd   1460 non-null   int64  \n 21  RoofStyle      1460 non-null   object \n 22  RoofMatl       1460 non-null   object \n 23  Exterior1st    1460 non-null   object \n 24  Exterior2nd    1460 non-null   object \n 25  MasVnrType     1452 non-null   object \n 26  MasVnrArea     1452 non-null   float64\n 27  ExterQual      1460 non-null   object \n 28  ExterCond      1460 non-null   object \n 29  Foundation     1460 non-null   object \n 30  BsmtQual       1423 non-null   object \n 31  BsmtCond       1423 non-null   object \n 32  BsmtExposure   1422 non-null   object \n 33  BsmtFinType1   1423 non-null   object \n 34  BsmtFinSF1     1460 non-null   int64  \n 35  BsmtFinType2   1422 non-null   object \n 36  BsmtFinSF2     1460 non-null   int64  \n 37  BsmtUnfSF      1460 non-null   int64  \n 38  TotalBsmtSF    1460 non-null   int64  \n 39  Heating        1460 non-null   object \n 40  HeatingQC      1460 non-null   object \n 41  CentralAir     1460 non-null   object \n 42  Electrical     1459 non-null   object \n 43  1stFlrSF       1460 non-null   int64  \n 44  2ndFlrSF       1460 non-null   int64  \n 45  LowQualFinSF   1460 non-null   int64  \n 46  GrLivArea      1460 non-null   int64  \n 47  BsmtFullBath   1460 non-null   int64  \n 48  BsmtHalfBath   1460 non-null   int64  \n 49  FullBath       1460 non-null   int64  \n 50  HalfBath       1460 non-null   int64  \n 51  BedroomAbvGr   1460 non-null   int64  \n 52  KitchenAbvGr   1460 non-null   int64  \n 53  KitchenQual    1460 non-null   object \n 54  TotRmsAbvGrd   1460 non-null   int64  \n 55  Functional     1460 non-null   object \n 56  Fireplaces     1460 non-null   int64  \n 57  FireplaceQu    770 non-null    object \n 58  GarageType     1379 non-null   object \n 59  GarageYrBlt    1379 non-null   float64\n 60  GarageFinish   1379 non-null   object \n 61  GarageCars     1460 non-null   int64  \n 62  GarageArea     1460 non-null   int64  \n 63  GarageQual     1379 non-null   object \n 64  GarageCond     1379 non-null   object \n 65  PavedDrive     1460 non-null   object \n 66  WoodDeckSF     1460 non-null   int64  \n 67  OpenPorchSF    1460 non-null   int64  \n 68  EnclosedPorch  1460 non-null   int64  \n 69  3SsnPorch      1460 non-null   int64  \n 70  ScreenPorch    1460 non-null   int64  \n 71  PoolArea       1460 non-null   int64  \n 72  PoolQC         7 non-null      object \n 73  Fence          281 non-null    object \n 74  MiscFeature    54 non-null     object \n 75  MiscVal        1460 non-null   int64  \n 76  MoSold         1460 non-null   int64  \n 77  YrSold         1460 non-null   int64  \n 78  SaleType       1460 non-null   object \n 79  SaleCondition  1460 non-null   object \n 80  SalePrice      1460 non-null   int64  \ndtypes: float64(3), int64(35), object(43)\nmemory usage: 924.0+ KB\n\n\n\ndf.head()\n\n\n\n  \n    \n      \n\n\n  \n    \n      \n      Id\n      MSSubClass\n      MSZoning\n      LotFrontage\n      LotArea\n      Street\n      Alley\n      LotShape\n      LandContour\n      Utilities\n      ...\n      PoolArea\n      PoolQC\n      Fence\n      MiscFeature\n      MiscVal\n      MoSold\n      YrSold\n      SaleType\n      SaleCondition\n      SalePrice\n    \n  \n  \n    \n      0\n      1\n      60\n      RL\n      65.0\n      8450\n      Pave\n      NaN\n      Reg\n      Lvl\n      AllPub\n      ...\n      0\n      NaN\n      NaN\n      NaN\n      0\n      2\n      2008\n      WD\n      Normal\n      208500\n    \n    \n      1\n      2\n      20\n      RL\n      80.0\n      9600\n      Pave\n      NaN\n      Reg\n      Lvl\n      AllPub\n      ...\n      0\n      NaN\n      NaN\n      NaN\n      0\n      5\n      2007\n      WD\n      Normal\n      181500\n    \n    \n      2\n      3\n      60\n      RL\n      68.0\n      11250\n      Pave\n      NaN\n      IR1\n      Lvl\n      AllPub\n      ...\n      0\n      NaN\n      NaN\n      NaN\n      0\n      9\n      2008\n      WD\n      Normal\n      223500\n    \n    \n      3\n      4\n      70\n      RL\n      60.0\n      9550\n      Pave\n      NaN\n      IR1\n      Lvl\n      AllPub\n      ...\n      0\n      NaN\n      NaN\n      NaN\n      0\n      2\n      2006\n      WD\n      Abnorml\n      140000\n    \n    \n      4\n      5\n      60\n      RL\n      84.0\n      14260\n      Pave\n      NaN\n      IR1\n      Lvl\n      AllPub\n      ...\n      0\n      NaN\n      NaN\n      NaN\n      0\n      12\n      2008\n      WD\n      Normal\n      250000\n    \n  \n\n5 rows × 81 columns\n\n      \n        \n  \n    \n    \n  \n      \n      \n  \n\n      \n    \n  \n  \n\n\n\nTasks:\n\nIdentify the columns with missing values (Hint: use the any function) and read up their description on the kaggle site\nReplace missing values with “appropriate” values, as follows:\n\n\nfor “categorical” data (e.g. strings ) use the most frequent value (mode)\nfor numerical data: plot a histogram and look at the distribution. For rather symmetric looking data, choose the mean, otherwise the median.\nfor “time” variables such as year: find another year variable as a proxy (Hint: read up on the combine_first function)\n\n\nFind those columns with fewer than 8 unique values (Hint: use the pandas method nunique())\n\n\nCreate 2 insightful boxplots: SalePrice versus YrSold or MSZoning. Decide if a log scale would be more discerning.\nUse groupbyto compute the boxes, i.e. the lower and upper quartiles. (Hint: use the numpy or pandas method quantile)\nThen compute the whiskers\nAnd find the outliers"
  },
  {
    "objectID": "Lab7.html",
    "href": "Lab7.html",
    "title": "8  Regression, seaborn",
    "section": "",
    "text": "Correlation and Regression as well as a quick exploration of the seaborn visualization capabilities\nkaggle Housing Data"
  },
  {
    "objectID": "Lab7.html#seaborn-graphs",
    "href": "Lab7.html#seaborn-graphs",
    "title": "8  Regression, seaborn",
    "section": "Seaborn Graphs",
    "text": "Seaborn Graphs\n\nsns.boxplot(df, y = \"SalePrice\", x = \"MSZoning\");\nplt.yscale(\"log\");plt.grid();\nplt.title(\"SalePrice vs. MSZoning\");\n\n\n\n\n\nMultiple Groups\n\nsns.boxplot(df, y = \"SalePrice\", x = \"MSZoning\", hue = \"YrSold\");\nplt.yscale(\"log\");\nplt.grid();\nplt.title(\"SalePrice vs. MSZoning\");"
  },
  {
    "objectID": "Lab7.html#violin-plots",
    "href": "Lab7.html#violin-plots",
    "title": "8  Regression, seaborn",
    "section": "Violin Plots",
    "text": "Violin Plots\n\nsns.violinplot(df, y = \"SalePrice\", x = \"MSZoning\");\nplt.yscale(\"log\");plt.grid();\nplt.title(\"SalePrice vs. MSZoning\");\n\n\n\n\n\nHistograms\n\nsns.histplot(data=df, x=\"SalePrice\", kde=True);plt.grid();\n\n\n\n\n\nsns.histplot(data=df, x=\"SalePrice\", kde=True, hue = \"MSZoning\");plt.grid();\n\n\n\n\n\n\nTasks:\n\nRegression/Correlation (Housing Data)\n\nLook up the pairplot function and create pairwise scatter plots of\n\n\n5-7 hand-picked numerical features, one of them being SalePrice\nHint: look at dtypes\n\n\nChoose the row with SalePrice and pick two reasonably strong correlations.\n\n\nCompute the correlation coefficients\nFit a simple regression line (with statsmodels) for each and visualize them using regplot\nFit a multiple regression by including both explanatory variables and compare the coefficients\n\n\ndf.dtypes != \"object\"\n\nId                True\nMSSubClass        True\nMSZoning         False\nLotFrontage       True\nLotArea           True\n                 ...  \nMoSold            True\nYrSold            True\nSaleType         False\nSaleCondition    False\nSalePrice         True\nLength: 81, dtype: bool\n\n\n\ndf.columns[df.dtypes != \"object\"][1:]\n\nIndex(['MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond',\n       'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2',\n       'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces',\n       'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF',\n       'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal',\n       'MoSold', 'YrSold', 'SalePrice'],\n      dtype='object')"
  },
  {
    "objectID": "Lab7.html#extra-credit",
    "href": "Lab7.html#extra-credit",
    "title": "8  Regression, seaborn",
    "section": "Extra Credit",
    "text": "Extra Credit\n\nModeling Missing Values Titanic Data\n\ndetect the missing values\nreplace the NAs in survived with the estimate grouped by sex\n\n\n#titanic\ntitanic = sns. load_dataset('titanic')\ntitanic[\"3rdClass\"] = titanic[\"pclass\"]==3\ntitanic[\"male\"] = titanic[\"sex\"]==\"male\"\n#titanic.head()\n\n#Introduce some missing values\nrng = default_rng()\n\nmissingRows = rng.integers(0,890,20)\nprint(missingRows)\n#introduce missing values\ntitanic.iloc[missingRows] = np.nan"
  },
  {
    "objectID": "DS_Homework1.html",
    "href": "DS_Homework1.html",
    "title": "9  Boxplots/Correlation",
    "section": "",
    "text": "Boxplots\n\nQuantiles\nWhiskers\n\nHistograms and Standard Deviation\nTask 0"
  },
  {
    "objectID": "DS_Homework1.html#explore-the-titanic-data",
    "href": "DS_Homework1.html#explore-the-titanic-data",
    "title": "9  Boxplots/Correlation",
    "section": "Explore the Titanic Data",
    "text": "Explore the Titanic Data\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\n\n\ntitanic = sns.load_dataset('titanic')\ntitanic.head()\n\n\n\n\n\n  \n    \n      \n      survived\n      pclass\n      sex\n      age\n      sibsp\n      parch\n      fare\n      embarked\n      class\n      who\n      adult_male\n      deck\n      embark_town\n      alive\n      alone\n    \n  \n  \n    \n      0\n      0\n      3\n      male\n      22.0\n      1\n      0\n      7.2500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      False\n    \n    \n      1\n      1\n      1\n      female\n      38.0\n      1\n      0\n      71.2833\n      C\n      First\n      woman\n      False\n      C\n      Cherbourg\n      yes\n      False\n    \n    \n      2\n      1\n      3\n      female\n      26.0\n      0\n      0\n      7.9250\n      S\n      Third\n      woman\n      False\n      NaN\n      Southampton\n      yes\n      True\n    \n    \n      3\n      1\n      1\n      female\n      35.0\n      1\n      0\n      53.1000\n      S\n      First\n      woman\n      False\n      C\n      Southampton\n      yes\n      False\n    \n    \n      4\n      0\n      3\n      male\n      35.0\n      0\n      0\n      8.0500\n      S\n      Third\n      man\n      True\n      NaN\n      Southampton\n      no\n      True\n    \n  \n\n\n\n\n\nBoxplots\n\nboxplot = titanic[['fare','pclass']].boxplot(by='pclass',return_type='dict' )"
  },
  {
    "objectID": "DS_Homework1.html#task-1",
    "href": "DS_Homework1.html#task-1",
    "title": "9  Boxplots/Correlation",
    "section": "Task 1",
    "text": "Task 1\n\nRead up the basics of boxplots: https://en.wikipedia.org/wiki/Box_plot, in particular the paragraph explaining the whiskers.\nRead up the definition of Quartiles and Quantiles and IQR. A good source would be the ThinkStats book (in the cloud folder).\n(MC) What are the exact values of the lower and upper whiskers (of fare) for the pclass2 passengers?\n\nA \\([0, 41.6]\\)\nB \\([0, 45.5]\\)\nC \\([-6.5, 45.5]\\)\nD \\([0, 46.1]\\)\n\n\nRecall the Wikipedia definition:From above the upper quartile, a distance of 1.5 times the IQR is measured out and a whisker is drawn up to the largest observed point from the dataset that falls within this distance. Similarly, a distance of 1.5 times the IQR is measured out below the lower quartile and a whisker is drawn up to the lower observed point from the dataset that falls within this distance.\n\nTask 1.3\n\n(MC) What are the exact values of the lower and upper whiskers (of fare) for the pclass2 passengers?\n\n\ntitanic[['fare','pclass']].groupby('pclass').describe()\n\n\n\n\n\n  \n    \n      \n      fare\n    \n    \n      \n      count\n      mean\n      std\n      min\n      25%\n      50%\n      75%\n      max\n    \n    \n      pclass\n      \n      \n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      1\n      216.0\n      84.154687\n      78.380373\n      0.0\n      30.92395\n      60.2875\n      93.5\n      512.3292\n    \n    \n      2\n      184.0\n      20.662183\n      13.417399\n      0.0\n      13.00000\n      14.2500\n      26.0\n      73.5000\n    \n    \n      3\n      491.0\n      13.675550\n      11.778142\n      0.0\n      7.75000\n      8.0500\n      15.5\n      69.5500"
  },
  {
    "objectID": "DS_Homework1.html#explore-the-auto-data",
    "href": "DS_Homework1.html#explore-the-auto-data",
    "title": "9  Boxplots/Correlation",
    "section": "Explore the Auto Data",
    "text": "Explore the Auto Data\n\ndf = pd.read_csv('../data/Auto.csv')\ndf.head()\n#df.info()\n\n\n\n\n\n  \n    \n      \n      mpg\n      cylinders\n      displacement\n      horsepower\n      weight\n      acceleration\n      year\n      origin\n      name\n      Manufacturer\n    \n  \n  \n    \n      0\n      18.0\n      8\n      307.0\n      130\n      3504\n      12.0\n      70\n      1\n      chevrolet chevelle malibu\n      chevrolet\n    \n    \n      1\n      15.0\n      8\n      350.0\n      165\n      3693\n      11.5\n      70\n      1\n      buick skylark 320\n      buick\n    \n    \n      2\n      18.0\n      8\n      318.0\n      150\n      3436\n      11.0\n      70\n      1\n      plymouth satellite\n      plymouth\n    \n    \n      3\n      16.0\n      8\n      304.0\n      150\n      3433\n      12.0\n      70\n      1\n      amc rebel sst\n      amc\n    \n    \n      4\n      17.0\n      8\n      302.0\n      140\n      3449\n      10.5\n      70\n      1\n      ford torino\n      ford\n    \n  \n\n\n\n\n\n# global mean\ndf.mean()\n\nmpg               23.445918\ncylinders          5.471939\ndisplacement     194.411990\nhorsepower       104.469388\nweight          2977.584184\nacceleration      15.541327\nyear              75.979592\norigin             1.576531\ndtype: float64\n\n\n\n# mpg mean\na = df[\"mpg\"].mean()\nb = df.iloc[:,0].mean()\nc = np.mean(df[\"mpg\"])\n\nprint(f'mpg mean:\\na = {a}\\nb = {b}\\nc = {c}')\n\nmpg mean:\na = 23.44591836734694\nb = 23.44591836734694\nc = 23.44591836734694\n\n\n\n#. Plot a histogram of mpg\nplt.hist(df[\"mpg\"], 20)\n\n(array([ 3., 10., 40., 38., 36., 37., 29., 29., 20., 33., 24., 24., 20.,\n        17., 13.,  9.,  3.,  1.,  5.,  1.]),\n array([ 9.  , 10.88, 12.76, 14.64, 16.52, 18.4 , 20.28, 22.16, 24.04,\n        25.92, 27.8 , 29.68, 31.56, 33.44, 35.32, 37.2 , 39.08, 40.96,\n        42.84, 44.72, 46.6 ]),\n <BarContainer object of 20 artists>)\n\n\n\n\n\n\n#scatterplot\nplt.scatter(\"weight\", \"mpg\",data=df)\nplt.xlabel(\"weight\")\nplt.ylabel(\"mpg\")\n\nText(0, 0.5, 'mpg')"
  },
  {
    "objectID": "DS_Homework1.html#task-2",
    "href": "DS_Homework1.html#task-2",
    "title": "9  Boxplots/Correlation",
    "section": "Task 2",
    "text": "Task 2\n\nCompute the mean mpg grouped by cylinder.\nCreate a boxplot of mpg vs. cylinder\nFind the median and lower/upper quartiles\nRead up the definition of correlation. ( ThinkStats book in the cloud folder). Compute the correlation coefficient between mpg and weight.\nCompute the correlation coefficient \\(\\rho\\) between mpg and origin. Discuss whether (i) there is a conceptual difference between the previous task, and (ii) whether it even makes sense to compute \\(\\rho\\) for this pair of variables. In that context, learn about categorical data types in pandas.\nWhat is the correlation coefficient “good for” ? Can you e.g. use it to make predictions, like in our previous simple probability model ? If not, what is missing ? Think about a loss function which would make sense for such a prediction task."
  }
]